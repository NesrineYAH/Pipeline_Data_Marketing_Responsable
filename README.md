# ğŸš€ Numberly - Pipeline Data Marketing Responsable

**Pipeline ETL + Dashboard pour l'analyse de donnÃ©es marketing respectueuse de la vie privÃ©e**

---

## ğŸ“‹ Table des MatiÃ¨res
- [ğŸ¯ Objectif](#-objectif)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ› ï¸ Technologies](#ï¸-technologies)
- [ğŸš€ Installation](#-installation)
- [ğŸ“Š Utilisation](#-utilisation)
- [ğŸ¨ FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [ğŸ“ Structure du Projet](#-structure-du-projet)
- [ğŸ¤ Contribution](#-contribution)

ğŸ¤ Contribution
Ce projet a Ã©tÃ© dÃ©veloppÃ© Nesrine YAHOUM Data Engineer, DÃ©veloppeuse full stack  pour dÃ©montrer des compÃ©tences en data engineering dans le cadre d'une candidature  dans le cadre d'une recherche d'alternance Data Engineer/Data Analystchez  Numberly.

<p><em>"Transformer la data en insights actionnables"</em> ğŸš€</p>

## ğŸ¯ Objectif

Simuler un pipeline data engineering complet pour Numberly, spÃ©cialiste du Data Marketing, en mettant en Å“uvre :
- **GÃ©nÃ©ration de donnÃ©es synthÃ©tiques** respectueuses de la vie privÃ©e
- **Pipeline ETL** (Extract, Transform, Load) robuste
- **Dashboard interactif** pour l'analyse marketing
- **Containerisation Docker** pour la reproductibilitÃ©

---

## ğŸ—ï¸ Architecture

```mermaid
graph TB
    A[ğŸ“¥ GÃ©nÃ©ration DonnÃ©es] --> B[ğŸ”„ Transformation ETL]
    B --> C[ğŸ’¾ Sauvegarde CSV]
    C --> D[ğŸ“Š Dashboard Streamlit]
    E[ğŸ³ Docker] --> A
    E --> D
    

##  Manuellement

- ** pip install -r requirements.txt
- ** python etl_pipeline.py
- ** streamlit run dashboard/streamlit_app.py

## Lancer uniquement l'ETL
docker-compose run etl-pipeline

##  Lancer uniquement le dashboard
docker-compose up dashboard

## Dashboard Analytics
- ** KPIs : Clients, Conversion, Chiffre d'affaires
- ** Performance par canal (SEO, Social, Email, Direct)
- **Segmentation clients (Premium, Standard, Basique)

<h2 id="fonctionnalites">ğŸ¨ FonctionnalitÃ©s</h2>

<h3>ğŸ“ˆ Dashboard Analytics</h3>

KPIs Principaux : Clients uniques, taux de conversion, chiffre d'affaires
    Performance par Canal : SEO, Social, Email, Direct
    Segmentation Clients : Premium, Standard, Basique
    Analyse Temporelle: Ã‰volution des interactions et achats
    Visualisations Interactives : Graphiques Plotly


<h3>ğŸ”§ Pipeline Data</h3>

 - ** GÃ©nÃ©ration de donnÃ©es rÃ©alistes avec Faker
 - ** Nettoyage et transformation des donnÃ©es
 - ** Calcul de mÃ©triques business (RFM, conversion, etc.)
 - ** Export format CSV pour analyse ultÃ©rieure

<h2> ğŸ“ Structure du Projet</h2>
<img src="./assets/structure projets.png" alt="structure projet" >








##  Visualisations interactives Plotly
<h2> ğŸ“Š Jeu de DonnÃ©es </h2>
DonnÃ©es GÃ©nÃ©rÃ©es
1 000 clients avec :
- **
- ** DÃ©mographie (Ã¢ge, ville)
- ** Segment (Premium, Standard, Basique)
- ** Canal d'acquisition

5 000 interactions avec :

- ** Types d'actions (page_vue, ajout_panier, achat)
- ** Valeurs d'achat
- ** Timestamps rÃ©alistes

MÃ©triques CalculÃ©es
- ** Taux de conversion par canal
- ** Chiffre d'affaires total
Panier moyen
- ** Segmentation comportementale


Stack technique alignÃ©e sur les besoins Numberly :

âœ… Python, SQL, ETL
âœ… Docker, Containerisation
âœ… Data Analysis, Visualisation
âœ… Marketing Data responsable

## Pipeline Data
GÃ©nÃ©ration 1 000 clients + 5 000 interactions

Calcul mÃ©triques business (RFM, conversion)

Export CSV pour analyse

ğŸŒ AccÃ¨s
Dashboard : http://localhost:8501

DonnÃ©es : GÃ©nÃ©rÃ©es automatiquement dans data/